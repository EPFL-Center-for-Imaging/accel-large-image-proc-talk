{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# 3 - Introduction to `Dask-image`\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dask-image` is a `Dask` sub-package specialized for handling images.\n",
    "\n",
    "It supports many of the functions from `scipy.ndimage` for `Dask.arrays`\n",
    "\n",
    "* dask_image.dispatch\n",
    "* dask_image.imread\n",
    "* dask_image.ndfilters\n",
    "* dask_image.ndfourier\n",
    "* dask_image.ndinterp\n",
    "* dask_image.ndmeasure\n",
    "* dask_image.ndmorph\n",
    "\n",
    "If you are interested, check out the [following example](https://genevievebuckley.github.io/dask-image-talk-2020/), from which this Notebook was partly inspired. \n",
    "\n",
    "In this notebook, we will use `Dask-image` for **lazy loading** a large image and **filtering** it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Lazy loading with Dask_image.imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dask.array as da\n",
    "import dask_image.imread\n",
    "\n",
    "from utils import show_images\n",
    "\n",
    "filename_pattern = os.path.join(\"imgs\", \"hubble\", \"image-*.png\")\n",
    "tiled_hubble_images = dask_image.imread.imread(filename_pattern)\n",
    "\n",
    "# Convert image to float\n",
    "tiled_hubble_images = tiled_hubble_images.astype(float) / 255.0\n",
    "tiled_hubble_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMINDER: Dask is lazy by default\n",
    "from sys import getsizeof\n",
    "print(f\"Size of `dask-image`: {getsizeof(tiled_hubble_images)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    [\n",
    "        tiled_hubble_images[0],\n",
    "        tiled_hubble_images[5],\n",
    "        tiled_hubble_images[10],\n",
    "        tiled_hubble_images[15],\n",
    "        tiled_hubble_images[20],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Applying your own custom function to images\n",
    "\n",
    "Next you'll want to do some image processing, and apply a function to your images.\n",
    "\n",
    "We'll use a very simple example: converting an RGB image to grayscale. \n",
    "\n",
    "To convert our image to grayscale, we'll use the equation to calculate luminance:\n",
    "\n",
    "```Y = 0.2125 R + 0.7154 G + 0.0721 B```\n",
    "\n",
    "We'll write the function for this equation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(rgb):\n",
    "    result = (rgb[..., 0] * 0.2125) + (rgb[..., 1] * 0.7154) + (rgb[..., 2] * 0.0721)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this operation requires to have a full extra copy of the input image in memory. Many operations require the creation, even temporarily, of array of the same size as the image. This can easily pose a bottleneck in our pipeline!\n",
    "\n",
    "Let's apply our custom function to the a **single chunk** of our image and visualize the computation graph.\n",
    "\n",
    "*TIP: Visualizing the computation graph isn't necessary but most of the time it's helpful to know what dask is doing under the hood, and it can also be very useful for debugging problems.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hubble_image = tiled_hubble_images[20].persist()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(hubble_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_single_image = grayscale(hubble_image)\n",
    "print(result_single_image)\n",
    "result_single_image.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original image dimensions: \", hubble_image.shape)\n",
    "print(\"Processed image dimensions:\", result_single_image.shape)\n",
    "\n",
    "show_images(\n",
    "    [hubble_image, result_single_image],\n",
    "    titles=[\"Original image\", \"Processed image\"],\n",
    "    cmap=[None, \"gray\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarrassingly parallel problems\n",
    "\n",
    "The syntax is identical to apply a function to multiple images or dask chunks. This is an example of an embarrassingly parallel problem, and we see that Dask automatically creates a computation graph for each image chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grayscale(tiled_hubble_images[:5].persist())\n",
    "print(result)\n",
    "result.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grayscale(tiled_hubble_images)\n",
    "show_images(\n",
    "    [\n",
    "        result[0],\n",
    "        result[5],\n",
    "        result[10],\n",
    "        result[15],\n",
    "        result[20],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join processed chunks\n",
    "We will now concatenate the small image chunks together into the shape of the image. \n",
    "\n",
    "This is important when doing convolutions or other analysis that process the neighborhood of each pixel.\n",
    "\n",
    "This joined image will still be a **lazy array**, but each chunk will access the edge values of the neighboring chunks. \n",
    "\n",
    "*Note: We could have done this in the beggining too.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy Dataset for visualisation\n",
    "data = [result[20], result[21]]\n",
    "toy_combined_image = da.block(data)\n",
    "toy_combined_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some Dask-image processing\n",
    "\n",
    "For illustration purposes, let's perform some [edge enhancement](https://www.wikiwand.com/en/Edge_enhancement) of our sky image.\n",
    "\n",
    "A very simple approach for edge enhancement is the following: \n",
    "\n",
    "$$\\hat{\\mathbf{I}} = (1-\\alpha) \\mathbf{I} + \\alpha \\vert  \\mathbf{I} - \\bar{\\mathbf{I}}_{\\sigma} \\vert $$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\hat{\\mathbf{I}}$ is the enhenced image,\n",
    "- $\\mathbf{I}$ is the original image, \n",
    "- $\\bar{\\mathbf{I}}_{\\sigma} $ is a smoothed version of $\\mathbf{I}$, with smoothing parameter $\\sigma$, and\n",
    "- $\\alpha \\in [0, 1]$ controls the level of enhancement. \n",
    "\n",
    "\n",
    "Let's complete the following function `edge_enhancement(image, sigma)` that uses `dask_image.ndfilters.gaussian_filter`:\n",
    "\n",
    "```python\n",
    "def edge_enhancement(image, sigma):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: Dask.array (2d)\n",
    "        Input image to enhance.\n",
    "    sigma: float\n",
    "        Smoothing parameter.\n",
    "    alpha: float [0, 1]\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_image: Dask.array (2d)\n",
    "        Edge enhanced image.\n",
    "    \"\"\"\n",
    "    \n",
    "    return NotImplementedError\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_image.ndfilters\n",
    "\n",
    "def edge_enhancement(image, sigma, alpha):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: Dask.array (2d)\n",
    "        Input image to enhance.\n",
    "    sigma: float\n",
    "        Smoothing parameter.\n",
    "    alpha: float [0, 1]\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_image: Dask.array (2d)\n",
    "        Edge enhanced image.\n",
    "    \"\"\"\n",
    "    assert sigma > 0\n",
    "    assert  0 <= alpha <= 1\n",
    "    smoothed_image = dask_image.ndfilters.gaussian_filter(image, sigma=sigma)\n",
    "    edge_image = abs(image - smoothed_image)\n",
    "    edge_enhanced_image = alpha * image + alpha * abs(image - smoothed_image)\n",
    "    \n",
    "    return edge_enhanced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_enhanced_toy = edge_enhancement(toy_combined_image.persist(), \n",
    "                                     sigma=20, \n",
    "                                     alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to match the different parts of the task graph with the edge enhancement equation: \n",
    "\n",
    "$$\\hat{\\mathbf{I}} = (1-\\alpha) \\mathbf{I} + \\alpha \\vert  \\mathbf{I} - \\bar{\\mathbf{I}}_{\\sigma} \\vert $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edge_enhanced_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "edge_enhanced_toy.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The toy dataset is useful to understand the task graph, and it can also be used to select good values for $\\sigma$ and $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "alphas = [0.1, 0.5]\n",
    "sigmas = [1, 10, 20]\n",
    "\n",
    "for alpha, sigma in itertools.product(alphas, sigmas):\n",
    "    edge_enhanced_toy = edge_enhancement(toy_combined_image.persist(), \n",
    "                                     sigma=sigma, \n",
    "                                     alpha=alpha)\n",
    "    show_images(\n",
    "        [toy_combined_image, edge_enhanced_toy],\n",
    "        titles=[\"Original\", fr\"Enh ($\\sigma={sigma}$, $\\alpha={alpha}$)\"],\n",
    "        cmap=\"cubehelix\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: run full pipeline on RGB dataset, and save for later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhancing parameters\n",
    "sigma = 20\n",
    "alpha = 0.5\n",
    "\n",
    "# Full Dataset\n",
    "edge_enhanced_image = []\n",
    "combined_image = []\n",
    "# For each RGB\n",
    "for j in range(3):\n",
    "    # Join chunks to have access to neighborhoods\n",
    "    data = [\n",
    "        [img[..., j] for img in tiled_hubble_images[i * 28 : (i + 1) * 28]]\n",
    "        for i in range(24)\n",
    "    ]\n",
    "    combined_image.append(da.block(data))\n",
    "    \n",
    "    # Join chunks to have access to neighborhoods\n",
    "    edge_enh = edge_enhancement(combined_image[j], sigma=sigma, alpha=alpha)\n",
    "    edge_enhanced_image.append(edge_enh)\n",
    "\n",
    "# Convert list to dask array\n",
    "edge_enhanced_image = da.dstack(edge_enhanced_image)\n",
    "combined_image = da.dstack(combined_image)\n",
    "edge_enhanced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    [\n",
    "        combined_image.blocks[0, 20],\n",
    "        edge_enhanced_image.blocks[0, 20],\n",
    "        (combined_image-edge_enhanced_image).blocks[0, 20],\n",
    "    ],\n",
    "    titles=[\"Original\", fr\"Edge Enhanced ($\\sigma={sigma}$, $\\alpha={alpha}$)\", \"Difference\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Data\n",
    "To simplify data loading in the future, we store this large chunked-array as a [Zarr file](https://zarr.readthedocs.io/en/stable/) using the `dask.array.to_zarr` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_enhanced_image.to_zarr(os.path.join(\"imgs\", \"hubble_enh.zarr\"), overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
